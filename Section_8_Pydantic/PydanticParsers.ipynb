{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59ad9b4f",
   "metadata": {},
   "source": [
    "## Pydantic Output Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fec8f91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)\n",
    "load_dotenv('./../.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa9e3477",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "llm = ChatOllama(\n",
    "    base_url=\"http://localhost:11434\",\n",
    "    model=\"qwen3:latest\",\n",
    "    temperature=0.5,\n",
    "    max_tokens=300\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93d7cb8",
   "metadata": {},
   "source": [
    "### Import Pydantic Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a7b90e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from langchain_core.runnables import chain\n",
    "from langchain_core.messages import AIMessage\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d111717a",
   "metadata": {},
   "source": [
    "### Create Joke class as extension of BaseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75e714a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Joke(BaseModel):\n",
    "    \"\"\"Joke Model to Entertain the User\"\"\"\n",
    "    \n",
    "    setup: str = Field(description=\"The setup of the joke\")\n",
    "    punchline: str = Field(description=\"Punchline of the joke\")\n",
    "    rating: Optional[int] = Field(description=\"Rating of the joke, from 1 to 10\", examples=(5, 7))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ded8609",
   "metadata": {},
   "source": [
    "### Create Parser using the PydanticOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ca051ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"description\": \"Joke Model to Entertain the User\", \"properties\": {\"setup\": {\"description\": \"The setup of the joke\", \"title\": \"Setup\", \"type\": \"string\"}, \"punchline\": {\"description\": \"Punchline of the joke\", \"title\": \"Punchline\", \"type\": \"string\"}, \"rating\": {\"anyOf\": [{\"type\": \"integer\"}, {\"type\": \"null\"}], \"description\": \"Rating of the joke, from 1 to 10\", \"examples\": [5, 7], \"title\": \"Rating\"}}, \"required\": [\"setup\", \"punchline\", \"rating\"]}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "parser = PydanticOutputParser(pydantic_object=Joke)\n",
    "\n",
    "instruction = parser.get_format_instructions()\n",
    "\n",
    "print(instruction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536e22bd",
   "metadata": {},
   "source": [
    "### Provide LLM Input Prompt & Parse Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338955e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template=\n",
    "        \"\"\" \n",
    "        Answer the user query with a joke. Following is your formatting insturction.\n",
    "        {format_instruction}\n",
    "        \n",
    "        Query: {query}\n",
    "        Answer:\n",
    "        \"\"\",\n",
    "    input_variables=['query'],\n",
    "    partial_variables={'format_instruction': instruction}\n",
    ")\n",
    "\n",
    "@chain\n",
    "def remove_think_block_ai_message(AIMessage) -> str:\n",
    "    return re.sub(r\"<think>.*?</think>\", \"\", AIMessage.content, flags=re.DOTALL | re.IGNORECASE)\n",
    "\n",
    "chain = prompt | llm | remove_think_block_ai_message | parser\n",
    "\n",
    "response = chain.invoke({'query': \"Tell a joke about cats\"})\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2acad0",
   "metadata": {},
   "source": [
    "### Parse LLM response using WithStructuredOutput Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97fa8ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setup=\"Why don't cats play hide and seek with the furniture?\" punchline='Because the furniture always wins.' rating=5\n"
     ]
    }
   ],
   "source": [
    "structured_llm = llm.with_structured_output(Joke)\n",
    "\n",
    "output = structured_llm.invoke(\"Tell a joke about cats\")\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ce3332",
   "metadata": {},
   "source": [
    "### Parse LLM Response using JsonOutputParser to JSON Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81aa5d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'setup': \"Why don't dogs make good secret agents?\", 'punchline': 'Because they always bark!', 'rating': 7}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser, StrOutputParser\n",
    "\n",
    "parser = JsonOutputParser(pydantic_object=Joke)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\n",
    "        \"\"\" \n",
    "        Answer the user query with a joke. Following is your formatting insturction.\n",
    "        {format_instruction}\n",
    "        \n",
    "        Query: {query}\n",
    "        Answer:\n",
    "        \"\"\",\n",
    "    input_variables=['query'],\n",
    "    partial_variables={'format_instruction': parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "chain = prompt | llm | remove_think_block_ai_message | parser\n",
    "\n",
    "response = chain.invoke({'query': \"Tell a joke about Dogs\"})\n",
    "\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd5152f",
   "metadata": {},
   "source": [
    "### Use of CSV Output Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8b1c8d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Elon Musk', 'Bernard Arnault & Family', 'Jeff Bezos', 'Amancio Ortega', 'Bill Gates']\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import CommaSeparatedListOutputParser\n",
    "from langchain_core.runnables import chain\n",
    "\n",
    "parser = CommaSeparatedListOutputParser()\n",
    "\n",
    "format_instruction = parser.get_format_instructions()\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\n",
    "        \"\"\" \n",
    "        Answer the user query with a list of values. Following is your formatting insturction.\n",
    "        {format_instruction}\n",
    "        \n",
    "        Query: {query}\n",
    "        Answer:\n",
    "        \"\"\",\n",
    "    input_variables=['query'],\n",
    "    partial_variables={'format_instruction': parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "chain = prompt | llm | remove_think_block_ai_message | parser\n",
    "\n",
    "response = chain.invoke({\"query\": \"Who were the world's top 5 richest persons in 2022 ?\"})\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8763fe5d",
   "metadata": {},
   "source": [
    "### Use of DateTime Output Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7aeae057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1965-08-09 00:00:00\n"
     ]
    }
   ],
   "source": [
    "from langchain.output_parsers import DatetimeOutputParser\n",
    "\n",
    "parser = DatetimeOutputParser(format=\"%d-%m-%Y\")\n",
    "\n",
    "format_instruction = parser.get_format_instructions()\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\n",
    "        \"\"\" \n",
    "        Answer the user query with a correct date. Following is your formatting insturction.\n",
    "        {format_instruction}\n",
    "        \n",
    "        Query: {query}\n",
    "        Answer:\n",
    "        \"\"\",\n",
    "    input_variables=['query'],\n",
    "    partial_variables={'format_instruction': parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "chain = prompt | llm | remove_think_block_ai_message | parser\n",
    "\n",
    "response = chain.invoke({\"query\": \"When did Singapore get Independence ?\"})\n",
    "\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenvLangchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
